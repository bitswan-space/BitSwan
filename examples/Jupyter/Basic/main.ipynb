{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of Bspump Jupyter\n",
    "\n",
    "Bspump Jupyter module is a collection of utilities to help you develop and deploy your pipelines from and within jupyter notebooks\n",
    "\n",
    "All of the functions are located inside `bspump.jupyter` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bspump.jupyter as bpj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, common pattern along bspump applications is to use files in `.conf` format for configuration, you can do this in jupyter with `init_bitswan_jupyter('path_to_config_file')`.\n",
    "\n",
    "For demo purposes we create a simple configuration file `demo-config.conf` with configuration for two simple pipelines:\n",
    " - `basic` pipeline with a single source named `TestSource` that generates events with increasing counter, that are then passed through a pipeline to a `NullSink`\n",
    " - `kafka2kafka` pipeline to showcase Kafka integration, that reads from a Kafka topic and writes to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitSwan BSPump version devel\n"
     ]
    }
   ],
   "source": [
    "bpj.init_bitswan_jupyter('pipelines.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic pipeline\n",
    "\n",
    "To create a new pipeline, you can use `new_pipeline('name')` function, which will create a new pipeline with the given name and make it the current pipeline. You can then add sources, processors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpj.new_pipeline('basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each pipeline has to start with source.\n",
    "\n",
    "Source is a class that inherits from `bspump.Source` and has to implement `main` method, which is called when the source is started. This method is asynchronous and passes events to the pipeline via `self.process(event)` call.\n",
    "The `__init__` method has to take `app`, `pipeline`, `id` and `config` arguments and call `super().__init__(app, pipeline, id, config)` with `id` and `config` arguments being optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bspump\n",
    "\n",
    "class TestSource(bspump.Source):\n",
    "    def __init__(self, app, pipeline, id=None, config=None):\n",
    "        super().__init__(app, pipeline, id, config)\n",
    "        self.name = self.Config[\"name\"] # we can access the configuration file through self.Config attribute, it acts just like a python dictionary\n",
    "        self.counter = 0\n",
    "    \n",
    "    async def main(self):\n",
    "        while self.counter < 1_000_000:\n",
    "            await self.process({f\"{self.name}_counter\": self.counter}) # we create events, and then pass them to pipeline for further processing\n",
    "            self.counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with our source class created, we can then register it to the pipeline with decorator `@register_source`, this decorator takes a function with 2 arguments, `app` and `pipeline` that returns an instance of the source class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bpj.register_source\n",
    "def test_source(app, pipeline):\n",
    "    return TestSource(app, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of `bspump.jupyter` module, is that you can test your pipelines directly and in real time, however for that you need some events to test with.\n",
    "\n",
    "There are 2 main ways to generate events in `bspump.jupyter` environment:\n",
    " - `sample_events` function, that takes in a list of events and registers them to be further processed with the pipeline\n",
    " - `retrieve_sample_events` function, that calls your source in the background, and let's you retrieve the events directly from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sample_events` is useful when you want to test your processors, sinks, etc. and you already have the events prepared, while `retrieve_sample_events` is useful when you want to test your source and you don't have the events prepared. For this example, we will use `retrieve_sample_events` to test our `TestSource` source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_source_name_counter': 0}\n",
      "{'test_source_name_counter': 1}\n",
      "{'test_source_name_counter': 2}\n",
      "{'test_source_name_counter': 3}\n",
      "{'test_source_name_counter': 4}\n",
      "{'test_source_name_counter': 5}\n",
      "{'test_source_name_counter': 6}\n",
      "{'test_source_name_counter': 7}\n",
      "{'test_source_name_counter': 8}\n",
      "{'test_source_name_counter': 9}\n",
      "Collected 10 events\n"
     ]
    }
   ],
   "source": [
    "await bpj.retrieve_sample_events(limit=10) # mind the await keyword, it is necessary for this to work\n",
    "\n",
    "# uncomment the line below to use the sample_events function\n",
    "# bpj.sample_events([{\"test_event\": 1}, {\"test_event\": 2}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `retrieve_sample_events` function takes in a `limit` argument, which specifies how many events you want to retrieve from the source. It then starts the source in the background, retrieves the events and stops the source. The events are then registered and printed out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to do something with those events, process them further. To do this we use processors. Processor is a class that inherits from `bspump.Processor` and has to implement `process` method, which takes 2 arguments,\n",
    "`context` and `event`. It then returns the processed event. There is also a functional way to register processors to the pipeline, without creating a new class, which will be shown later. Again, `__init__` method has to take `app`, `pipeline`, `id` and `config` arguments and call `super().__init__(app, pipeline, id, config)` with `id` and `config` arguments being optional. This is a common pattern for all bspump components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestProcessor(bspump.Processor):\n",
    "    def __init__(self, app, pipeline, id=None, config=None):\n",
    "        super().__init__(app, pipeline, id, config)\n",
    "        self.counter = 0\n",
    "        self.name = self.Config[\"name\"]\n",
    "\n",
    "    def process(self, context, event):\n",
    "        self.counter += 1\n",
    "        event[self.name] = self.counter\n",
    "\n",
    "        return event\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register this processor to the pipeline, we use `@register_processor` decorator, which takes a function with 2 arguments, `app` and `pipeline` that returns an instance of the processor class. This will, similary to source, register the processor to the pipeline and show the processed events that were previously registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_source_name_counter': 0, 'test_processor_name': 1}\n",
      "{'test_source_name_counter': 1, 'test_processor_name': 2}\n",
      "{'test_source_name_counter': 2, 'test_processor_name': 3}\n",
      "{'test_source_name_counter': 3, 'test_processor_name': 4}\n",
      "{'test_source_name_counter': 4, 'test_processor_name': 5}\n",
      "{'test_source_name_counter': 5, 'test_processor_name': 6}\n",
      "{'test_source_name_counter': 6, 'test_processor_name': 7}\n",
      "{'test_source_name_counter': 7, 'test_processor_name': 8}\n",
      "{'test_source_name_counter': 8, 'test_processor_name': 9}\n",
      "{'test_source_name_counter': 9, 'test_processor_name': 10}\n"
     ]
    }
   ],
   "source": [
    "@bpj.register_processor\n",
    "def test_processor(app, pipeline):\n",
    "    return TestProcessor(app, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to object oriented approach to processors, a functional approach is possible. You can use `@step` or `@async_step` decorators, to decorate your functions that take event as an input. They should return, respectively, a processed event or a coroutine that returns a processed event. This is useful when you want to create a simple processor that doesn't require a class.\n",
    "\n",
    "In the background, this will create a new class that inherits from `bspump.Processor` and implements `process` method, that calls the decorated function. The name of the processor will be the function name converted to camel case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_source_name_counter': 0, 'test_processor_name': 1, 'processed': True}\n",
      "{'test_source_name_counter': 1, 'test_processor_name': 2, 'processed': True}\n",
      "{'test_source_name_counter': 2, 'test_processor_name': 3, 'processed': True}\n",
      "{'test_source_name_counter': 3, 'test_processor_name': 4, 'processed': True}\n",
      "{'test_source_name_counter': 4, 'test_processor_name': 5, 'processed': True}\n",
      "{'test_source_name_counter': 5, 'test_processor_name': 6, 'processed': True}\n",
      "{'test_source_name_counter': 6, 'test_processor_name': 7, 'processed': True}\n",
      "{'test_source_name_counter': 7, 'test_processor_name': 8, 'processed': True}\n",
      "{'test_source_name_counter': 8, 'test_processor_name': 9, 'processed': True}\n",
      "{'test_source_name_counter': 9, 'test_processor_name': 10, 'processed': True}\n"
     ]
    }
   ],
   "source": [
    "@bpj.step\n",
    "def test_step(event): #TestStepProcessor\n",
    "    event[\"processed\"] = True\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can end our pipeline with sink, in this case we will use `bspump.common.NullSink` which is a sink that does nothing with the events, it just consumes them. Using more useful sinks, like `bspump.kafka.KafkaSink` or `bspump.elasticsearch.ElasticSearchSink` is pretty much the same, and will be showcased later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to register the sink to the pipeline, we use `@register_sink` decorator, which takes a function with 2 arguments, `app` and `pipeline` that returns an instance of the sink class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bspump.common\n",
    "\n",
    "@bpj.register_sink\n",
    "def null_sink(app, pipeline):\n",
    "    return bspump.common.NullSink(app, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up the pipeline, we need to call `end_pipeline` function, which will end the current pipeline and add it to the finished ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpj.end_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
