{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447926d0-64da-40f5-827e-cd2889d5c03e",
   "metadata": {},
   "source": [
    "Bitswan Gitops Webhook Pipeline\n",
    "-------------------------------\n",
    "\n",
    "This pipeline allows you to easilly deploy Bitswan pipelines to any server. You just need to POST to the webhook in your CI and your pipelines will be running in no time.\n",
    "\n",
    "To install bitswan you need to initialize a git repository on your server/the place you want to run your bitswan installation and run the bitswan-pre docker image with the following ENV vars set:\n",
    "\n",
    "- `BS_WEBHOOK_PORT` - defaults to 8080\n",
    "- `BS_WEBHOOK_SECRET` - A secret that will be added to your webhook URL. To deploy post `{\"action\": \"deploy-git\"}` to the URL `https://localhost:<BS_WEBHOOK_PORT>/?secret=<BS_WEBHOOK_SECRET>`\n",
    "- `BS_BITSWAN_DIR` - The directory where your `bitswan.yaml` file resides. Should be in a checked out git repository. Defaults to `/mnt/repo/bitswan`.\n",
    "\n",
    "Simply adding the following curl command to your CI/CD pipeline should be enough to automatically deploy your data machines:\n",
    "\n",
    "```\n",
    "curl -X POST \"https://<WEBHOOK_URL>:<BS_WEBHOOK_PORT>/?secret=<BS_WEBHOOK_SECRET>\" -d '{\"action\": \"deploy-git\"}'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680223b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:05:00.873810Z",
     "start_time": "2024-02-19T12:05:00.684537Z"
    }
   },
   "outputs": [],
   "source": [
    "from bspump.jupyter import *\n",
    "import bspump.http.web.source\n",
    "import bspump.common\n",
    "import bspump.mqtt\n",
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "import yaml\n",
    "import datetime\n",
    "from dockerfile_parse import DockerfileParser\n",
    "from bspump.abc.generator import Generator\n",
    "import docker\n",
    "import docker.errors\n",
    "import subprocess\n",
    "import re\n",
    "import bspump.kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996149e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:04:25.866292Z",
     "start_time": "2024-02-19T12:04:25.847188Z"
    }
   },
   "outputs": [],
   "source": [
    "@register_connection\n",
    "def connection(app):\n",
    "    return bspump.mqtt.MQTTConnection(app, \"MQTTConnection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd3c76-2f57-4957-b0e3-6328e31fab62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:04:19.536051Z",
     "start_time": "2024-02-19T12:04:19.529606Z"
    }
   },
   "outputs": [],
   "source": [
    "new_pipeline(\"BitswanGitopsWebHookPipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fee55-b7e1-47ab-94f3-904dea5890f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:04:20.882326Z",
     "start_time": "2024-02-19T12:04:20.877243Z"
    }
   },
   "outputs": [],
   "source": [
    "@register_source\n",
    "def source(app, pipeline):\n",
    "    return bspump.http.web.source.WebHookSource(\n",
    "       app,\n",
    "       pipeline,\n",
    "       config = {\n",
    "           \"port\": int(os.environ.get(\"BS_WEBHOOK_PORT\", 8080)),\n",
    "           \"path\": \"/\",\n",
    "           \"secret_qparam\": os.environ.get(\"BS_WEBHOOK_SECRET\", \"not-secure\")\n",
    "       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee957c39-5d6e-4bc4-90ec-cd1a3ff6dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_events([\n",
    "    b\"\"\"{\"action\": \"deploy-git\"}\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e91027-d95c-41ec-9377-991ce5925c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def parse_json(event):\n",
    "    return json.loads(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba255d4-376e-4905-8ec1-15e32cbf36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def get_bitswan_dir(event):\n",
    "    event[\"bitswan_dir\"] = os.environ.get(\"BS_BITSWAN_DIR\", \"/mnt/repo/bitswan\")\n",
    "    event[\"host_base_path\"] = os.environ.get(\"BS_HOST_BASE_PATH\", \"/opt/bitswan-pipelines\")\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2764f-c183-4f60-9374-04add7c72b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_events([{'action': 'deploy-git', \"bitswan_dir\":\"/Users/lukasvecerka/Work/BitSwan/Development/repo/datamachines\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbe90b-9128-490d-8c09-33cf02caf240",
   "metadata": {},
   "outputs": [],
   "source": [
    "@async_step\n",
    "async def git_pull(inject, event):\n",
    "    bitswan_dir = event[\"bitswan_dir\"]\n",
    "    print(\"Pulling in new changes.\")\n",
    "    git_repo_root = os.path.abspath(bitswan_dir)  # Convert to absolute path\n",
    "\n",
    "    while git_repo_root != os.path.dirname(git_repo_root):  # Check until the root of the file system\n",
    "        if os.path.isdir(os.path.join(git_repo_root, '.git')):\n",
    "            break  # Return the path if .git directory is found\n",
    "        git_repo_root = os.path.dirname(git_repo_root)  # Move up one directory level\n",
    "    event[\"git_repo_root\"] = git_repo_root\n",
    "\n",
    "    await asyncio.create_subprocess_exec(\"git\", \"config\", \"--global\", \"--add\", \"safe.directory\", git_repo_root) \n",
    "    await asyncio.create_subprocess_exec(\"git\", \"config\", \"pull.rebase\", \"false\", cwd=bitswan_dir) \n",
    "    pull_process = await asyncio.create_subprocess_exec(\"git\", \"pull\", cwd=bitswan_dir)\n",
    "    await pull_process.wait()\n",
    "\n",
    "    if pull_process.returncode != 0:\n",
    "        print(\"Failed to pull in changes.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Done pulling in changes.\")\n",
    "    await inject(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f90d1-3e99-4f3a-8b5f-482dba943e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def load_bitswan_yaml(event):\n",
    "    event[\"yaml\"] = yaml.full_load(open(os.path.join(event[\"bitswan_dir\"], \"bitswan.yaml\")))\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ced64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deployment_info(client, deployment_ids):\n",
    "    deployment_info = {}\n",
    "    for id in deployment_ids:\n",
    "        deployment_info[id] = {\n",
    "            \"deployment_id\": id,\n",
    "            \"running\": False,\n",
    "            \"container\": None,\n",
    "            \"recreate\": False,\n",
    "            \"build_commit\": None\n",
    "        }\n",
    "\n",
    "    for container in client.containers.list():\n",
    "        container_envs = dict(var.split('=', 1) for var in container.attrs['Config']['Env'])\n",
    "        deployment_id = container_envs.get('DEPLOYMENT_ID')\n",
    "        if deployment_id in deployment_ids:\n",
    "            deployment_info[deployment_id][\"running\"] = True\n",
    "            deployment_info[deployment_id][\"container\"] = container\n",
    "            deployment_info[deployment_id][\"build_commit\"] = container.attrs['Config']['Labels']['built.from']\n",
    "    return deployment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_commit(path):\n",
    "    try:\n",
    "        commit_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], text=True, cwd=path).strip()\n",
    "        return commit_hash\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error obtaining current Git commit: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pump_folder_changed(last_commit, pump_path):\n",
    "    result = subprocess.run(['git', 'diff', '--name-only', last_commit, 'HEAD', pump_path], stdout=asyncio.subprocess.PIPE, text=True, cwd=pump_path)\n",
    "\n",
    "    return bool(result.stdout.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ac843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dockerfile(parser, dockerfile_path, envs):\n",
    "    with open(dockerfile_path, 'r') as f:\n",
    "        parser.content = f.read()\n",
    "    copy_statements = [instr for instr in parser.structure if instr['instruction'] in ['COPY', 'ADD']]\n",
    "\n",
    "    files = []\n",
    "    for copy_statement in copy_statements:\n",
    "        files.extend(copy_statement['value'].split()[:-1])\n",
    "\n",
    "    resolved_file_list = []\n",
    "\n",
    "    for file in files:\n",
    "        for env_var, value in envs.items():\n",
    "            if env_var in file:\n",
    "                file = file.replace(f'${{{env_var}}}', value).replace(f'${env_var}', value)\n",
    "                if '$' in file:\n",
    "                    continue\n",
    "        \n",
    "        resolved_file_list.append(file)\n",
    "    \n",
    "    return resolved_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pump_dependencies_changed(commit: str, files: list, path: str) -> bool:\n",
    "    changes = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        \n",
    "        result = subprocess.run(['git', 'diff', '--name-only', commit, file_path], \n",
    "                                stdout=subprocess.PIPE, text=True, cwd=path)\n",
    "        if result.stdout.strip():\n",
    "            changes.append(file)\n",
    "\n",
    "    return bool(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def container_management(event):\n",
    "    bitswan_dir = event[\"bitswan_dir\"]\n",
    "    git_repo_root = event[\"git_repo_root\"]\n",
    "    dmy = event[\"yaml\"]\n",
    "\n",
    "    dockerfile_parser = DockerfileParser()\n",
    "    docker_client = docker.from_env()\n",
    "\n",
    "    deployment_info = get_deployment_info(docker_client, dmy[\"data-machines\"].keys())\n",
    "    \n",
    "    for deployment_id, info in deployment_info.items():\n",
    "        # if running check if something changed\n",
    "        if info[\"running\"]:\n",
    "            pump_path = os.path.join(bitswan_dir, dmy[\"data-machines\"][deployment_id][\"source\"])\n",
    "            dockerfile_path = os.path.join(pump_path, \"Dockerfile\")\n",
    "\n",
    "            # check if pump folder changed\n",
    "            if pump_folder_changed(info[\"build_commit\"], pump_path):\n",
    "                info[\"recreate\"] = True\n",
    "                info[\"build_commit\"] = get_current_commit(bitswan_dir)\n",
    "                continue\n",
    "            \n",
    "            # check if pump's dependencies changed\n",
    "            container_envs = dict(var.split('=', 1) for var in info[\"container\"].attrs['Config']['Env'])\n",
    "            pump_dependencies = parse_dockerfile(dockerfile_parser, dockerfile_path, container_envs)\n",
    "\n",
    "            if pump_dependencies_changed(info[\"build_commit\"], pump_dependencies, git_repo_root):\n",
    "                info[\"recreate\"] = True\n",
    "                info[\"build_commit\"] = get_current_commit(bitswan_dir)\n",
    "\n",
    "        else:\n",
    "            info[\"recreate\"] = True\n",
    "            info[\"build_commit\"] = get_current_commit(bitswan_dir)\n",
    "    print(deployment_info)\n",
    "    event[\"deployment_info\"] = deployment_info\n",
    "    return (event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa05873-a827-4f7d-b26c-3f9a63ba366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def generate_docker_compose(event):\n",
    "    bitswan_dir = event[\"bitswan_dir\"]\n",
    "    bitswan_yaml = event[\"yaml\"]\n",
    "    deployment_info = event[\"deployment_info\"]\n",
    "    git_repo_root = event[\"git_repo_root\"]\n",
    "\n",
    "    dc = {\n",
    "        \"version\": \"3\",\n",
    "        \"services\": {},\n",
    "        \"networks\": {}\n",
    "    }\n",
    "    for network in bitswan_yaml.get(\"default-networks\", []):\n",
    "        dc[\"networks\"][network] = {\"external\": True}\n",
    "    for deployment_id, conf in bitswan_yaml[\"data-machines\"].items():\n",
    "        if conf is None:\n",
    "            conf = {}\n",
    "        entry = {}\n",
    "        deployment = deployment_info[deployment_id]\n",
    "        entry[\"environment\"] = {\"DEPLOYMENT_ID\": deployment_id}\n",
    "        entry[\"container_name\"] = deployment_id\n",
    "        entry[\"labels\"] = {\"built.from\": deployment[\"build_commit\"]}\n",
    "        if \"env-dir\" in bitswan_yaml:\n",
    "           env_file = os.path.join(bitswan_yaml[\"env-dir\"], deployment_id)\n",
    "           if os.path.exists(env_file):\n",
    "               entry[\"env_file\"] = [env_file]\n",
    "        if \"default-networks\" in bitswan_yaml:\n",
    "            entry[\"networks\"] = bitswan_yaml[\"default-networks\"].copy()\n",
    "        source = conf.get(\"source\", deployment_id)\n",
    "        data_machine_dir = os.path.join(bitswan_dir, source)\n",
    "        dockerfile_path = \"Dockerfile\"\n",
    "        entry[\"build\"] = {\n",
    "            \"dockerfile\": os.path.join(data_machine_dir, dockerfile_path),\n",
    "            \"context\": git_repo_root,\n",
    "            \"args\": {\n",
    "                \"DATA_MACHINE_SOURCE_PATH\": data_machine_dir.replace(git_repo_root, \".\"),\n",
    "            }\n",
    "        }\n",
    "        passthroughs = [\"volumes\", \"network_mode\", \"ports\", \"restart\", \"devices\", \"container_name\", ]\n",
    "        for passthrough in passthroughs:\n",
    "            if passthrough in conf:\n",
    "              entry[passthrough] = conf[passthrough]\n",
    "        if conf.get(\"enabled\", True):\n",
    "            dc[\"services\"][deployment_id] = entry\n",
    "\n",
    "        # IDE Container definition\n",
    "        ide_entry = {}\n",
    "        ide_entry[\"entrypoint\"] = \"/start-ide.sh\"\n",
    "        ide_entry[\"image\"] = \"dev_\" + deployment_id\n",
    "        ide_entry[\"volumes\"] = entry.get(\"volumes\", [])\n",
    "        ide_entry[\"networks\"] = entry[\"networks\"]\n",
    "        ide_entry[\"volumes\"] += [\n",
    "            os.path.join(event[\"host_base_path\"],\"dev/\")+\":/mnt\",\n",
    "        ]\n",
    "        ide_entry[\"container_name\"] = deployment_id + \"__ide__\"\n",
    "        dc[\"services\"][deployment_id+\"__ide__\"] = ide_entry\n",
    "\n",
    "    dc_yaml = yaml.dump(dc)\n",
    "    print(dc_yaml)\n",
    "    event[\"docker_compose\"] = dc_yaml\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a95fcc-448c-4a01-85d6-97bfdbcd8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "@async_step\n",
    "async def docker_compose_up_daemon(inject, event):\n",
    "    bitswan_dir = event[\"bitswan_dir\"]\n",
    "    docker_compose_yaml = event[\"docker_compose\"]\n",
    "    deployment_info = event[\"deployment_info\"]\n",
    "    \n",
    "    services_to_recreate = [service for service, info in deployment_info.items() if info[\"recreate\"]]\n",
    "    ide_services = [service+\"__ide__\" for service in deployment_info.keys()]\n",
    "    \n",
    "    build_result = None\n",
    "    if services_to_recreate:\n",
    "        cmd = [\"docker-compose\", \"-f\", \"/dev/stdin\", \"build\", \"--pull\"]\n",
    "        cmd.extend(services_to_recreate)\n",
    "\n",
    "        # Create a subprocess with stdin pipe\n",
    "        proc = await asyncio.create_subprocess_exec(\n",
    "            *cmd, \n",
    "            stdin=asyncio.subprocess.PIPE, \n",
    "            stdout=asyncio.subprocess.PIPE, \n",
    "            stderr=asyncio.subprocess.PIPE,\n",
    "            cwd=bitswan_dir\n",
    "        )\n",
    "\n",
    "        # Send docker_compose_yaml as input to the process and wait for completion\n",
    "        stdout, stderr = await proc.communicate(input=docker_compose_yaml.encode())\n",
    "\n",
    "        build_result = {\n",
    "            \"cmd\": cmd,\n",
    "            \"stdout\": stdout.decode(\"utf-8\"),\n",
    "            \"stderr\": stderr.decode(\"utf-8\"),\n",
    "            \"returncode\": proc.returncode,\n",
    "        }\n",
    "    \n",
    "    cmd = [\"docker-compose\", \"-f\", \"/dev/stdin\", \"up\", \"-d\"]\n",
    "    cmd.extend(services_to_recreate)\n",
    "\n",
    "    # Create a subprocess with stdin pipe\n",
    "    proc = await asyncio.create_subprocess_exec(\n",
    "        *cmd, \n",
    "        stdin=asyncio.subprocess.PIPE, \n",
    "        stdout=asyncio.subprocess.PIPE, \n",
    "        stderr=asyncio.subprocess.PIPE,\n",
    "        cwd=bitswan_dir\n",
    "    )\n",
    "\n",
    "    # Send docker_compose_yaml as input to the process and wait for completion\n",
    "    stdout, stderr = await proc.communicate(input=docker_compose_yaml.encode())\n",
    "\n",
    "    up_result = {\n",
    "        \"cmd\": cmd,\n",
    "        \"stdout\": stdout.decode(\"utf-8\"),\n",
    "        \"stderr\": stderr.decode(\"utf-8\"),\n",
    "        \"returncode\": proc.returncode,\n",
    "    }\n",
    "\n",
    "    # IDE Container creation\n",
    "    cmd = [\"docker-compose\", \"-f\", \"/dev/stdin\", \"up\", \"--no-start\"]\n",
    "    cmd.extend(ide_services)\n",
    "\n",
    "    proc = await asyncio.create_subprocess_exec(\n",
    "        *cmd,\n",
    "        stdin=asyncio.subprocess.PIPE,\n",
    "        stdout=asyncio.subprocess.PIPE, \n",
    "        stderr=asyncio.subprocess.PIPE,\n",
    "        cwd=bitswan_dir\n",
    "    )\n",
    "\n",
    "    stdout, stderr = await proc.communicate(input=docker_compose_yaml.encode())\n",
    "\n",
    "    ide_result = {\n",
    "        \"cmd\": cmd,\n",
    "        \"stdout\": stdout.decode(\"utf-8\"),\n",
    "        \"stderr\": stderr.decode(\"utf-8\"),\n",
    "        \"returncode\": proc.returncode\n",
    "    }\n",
    "\n",
    "    event = {\n",
    "        \"@timestamp\": datetime.datetime.now().timestamp(),\n",
    "        \"local-time\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"build\": build_result,\n",
    "        \"up\": up_result,\n",
    "        \"ide\": ide_result\n",
    "    }\n",
    "    await inject(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c3673-dab0-4b10-92f1-d8b391ecda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def serialize_yaml(event):\n",
    "    return yaml.dump(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd88fa5-f797-4c23-82ac-117538bb05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_sink\n",
    "def init_sink(app, pipeline):\n",
    "    return bspump.common.PrintSink(app, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aced63",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42227927",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline(\"IDELaunchPipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_source\n",
    "def mqtt_source(app, pipeline):\n",
    "    return bspump.mqtt.MQTTSource(app, pipeline, \"MQTTConnection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_processor\n",
    "def processor(app, pipeline):\n",
    "    return bspump.common.BytesToStringParser(app, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_processor\n",
    "def processor(app, pipeline):\n",
    "    return bspump.common.StdJsonToDictParser(app, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "@async_step\n",
    "async def start_ide(inject, event):\n",
    "    event[\"ide_container\"] = event[\"deployment_id\"] + \"__ide__\"\n",
    "    docker_client = docker.from_env()\n",
    "    \n",
    "    try:\n",
    "        container = docker_client.containers.get(event[\"ide_container\"])\n",
    "        container.start()\n",
    "    except docker.errors.NotFound:\n",
    "        print(f\"Container {event['ide_container']} not found.\")\n",
    "\n",
    "    await inject(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_ide_logs(container_name, mqtt_connection, log_topic, url_topic):\n",
    "    docker_client = docker.from_env()\n",
    "\n",
    "    url_pattern = re.compile(r\"http://localhost:\\d+/lab\\?token=[a-zA-Z0-9]+\")\n",
    "\n",
    "    try:\n",
    "        container = docker_client.containers.get(container_name)\n",
    "        for line in container.logs(stream=True):\n",
    "            log_line = line.decode('utf-8').rstrip()\n",
    "            \n",
    "            # Publish every log line to MQTT\n",
    "            message = {\n",
    "                \"message\": log_line,\n",
    "            }\n",
    "            mqtt_connection.publish_to_topic(log_topic, json.dumps(message))\n",
    "\n",
    "            # Check for Jupyter Lab URL in the log line\n",
    "            match = url_pattern.search(log_line)\n",
    "            if match:\n",
    "                jupyter_url = match.group(0)\n",
    "                # Publish the found URL to a separate MQTT topic\n",
    "                message = {\n",
    "                    \"url\": jupyter_url,\n",
    "                    \"redirect\": True\n",
    "                }\n",
    "                # Wait for the Jupyter Lab to start\n",
    "                await asyncio.sleep(1)\n",
    "                mqtt_connection.publish_to_topic(url_topic, json.dumps(message))\n",
    "                return\n",
    "    except docker.errors.NotFound:\n",
    "        print(f\"Container {container_name} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDELogsStreamer(Generator):\n",
    "    def __init__(self, app, pipeline, id=None, config=None):\n",
    "        super().__init__(app, pipeline, id, config)\n",
    "        self.MQTTConnection = pipeline.locate_connection(app, \"MQTTConnection\")\n",
    "    async def generate(self, context, event, depth):\n",
    "        container_name = event[\"ide_container\"]\n",
    "        deployment_id = event[\"deployment_id\"]\n",
    "        logs_topic = f\"{deployment_id}/editor/launch\"\n",
    "        url_topic = f\"{deployment_id}/editor/redirect\"\n",
    "\n",
    "        asyncio.create_task(stream_ide_logs(container_name, self.MQTTConnection, logs_topic, url_topic))\n",
    "\n",
    "        self.Pipeline.inject(context, event, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_generator\n",
    "def create_stream_logs(app, pipeline):\n",
    "    return IDELogsStreamer(app, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6995ad92f7f700",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def serialize_yaml(event):\n",
    "    return yaml.dump(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f3c9aa735ce89",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@register_sink\n",
    "def init_sink(app, pipeline):\n",
    "    return bspump.common.PrintSink(app, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84c6370609e60a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "end_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
